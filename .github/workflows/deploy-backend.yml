name: Deploy Backend to Cloud Run

on:
  push:
    branches: [ main ]
    paths:
      - 'backend/**'
      - '.github/workflows/deploy-backend.yml'
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

env:
  SERVICE_NAME: fastapi-svc
  AR_REPO_PATH: asia-east1-docker.pkg.dev/${{ secrets.PROJECT_ID }}/fastapi-repo/fastapi-svc

concurrency:
  group: deploy-backend
  cancel-in-progress: false

jobs:
  deploy:
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.PROJECT_ID }}

      # Build & Push (Cloud Build → Artifact Registry)
      - name: Build & Push
        run: |
          gcloud builds submit backend \
            --tag ${{ env.AR_REPO_PATH }}:${{ github.sha }}

      # Compose DATABASE_URL with URL-encoded DB_PASS
      - name: Compose DATABASE_URL
        id: dburl
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_PASS: ${{ secrets.DB_PASS }}
          ICN: ${{ secrets.INSTANCE_CONNECTION_NAME }}
        run: |
          URL_ENC_PASS="$(python3 -c "import urllib.parse,os; print(urllib.parse.quote(os.environ['DB_PASS'], safe=''))")"
          echo "DATABASE_URL=postgresql+psycopg://${DB_USER}:${URL_ENC_PASS}@/${DB_NAME}?host=/cloudsql/${ICN}" >> "$GITHUB_OUTPUT"
      
      # Deploy DB Migration Job
      - name: Deploy DB Migration Job (alembic upgrade head)
        run: |
          gcloud run jobs deploy fastapi-db-migrate \
            --image ${{ env.AR_REPO_PATH }}:${{ github.sha }} \
            --region ${{ secrets.REGION }} \
            --set-cloudsql-instances "${{ secrets.INSTANCE_CONNECTION_NAME }}" \
            --set-env-vars "DATABASE_URL=${{ steps.dburl.outputs.DATABASE_URL }},PYTHONUNBUFFERED=1,PYTHONPATH=/app" \
            --command bash \
            --args -lc \
            --args "python -m alembic -c alembic.ini upgrade head" \
            --max-retries 1 \
            --memory 512Mi \
            --cpu 1 \
            --task-timeout 900s

      - name: Run DB Migration Job (execute & print logs)
        env:
          REGION: ${{ secrets.REGION }}
        run: |
          set +e

          # 1) 先觸發執行
          gcloud run jobs execute fastapi-db-migrate --region "$REGION" --format='value(name)'

          # 2) 取出最新一筆 execution 名稱
          EXEC_NAME="$(gcloud run jobs executions list \
            --job fastapi-db-migrate \
            --region "$REGION" \
            --limit 1 --format='value(name)')"
          echo "Execution: ${EXEC_NAME}"

          # 3) 等待該 execution 完成
          gcloud run jobs executions wait "$EXEC_NAME" --region "$REGION"
          EXIT_CODE=$?
          echo "Job exit code: ${EXIT_CODE}"

          echo "---- Execution details ----"
          gcloud run jobs executions describe "$EXEC_NAME" --region "$REGION" --format=yaml || true

          echo "---- Recent Job Logs (container output) ----"
          gcloud logging read \
            'resource.type="cloud_run_job"
            AND labels."run.googleapis.com/execution_name"="'$EXEC_NAME'"' \
            --freshness=24h --limit=500 \
            --format='table(timestamp, severity, textPayload, jsonPayload.message)' || true

          exit ${EXIT_CODE}
          
      # Deploy to Cloud Run
      - name: Deploy
        env:
          DATABASE_URL: ${{ steps.dburl.outputs.DATABASE_URL }}
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.AR_REPO_PATH }}:${{ github.sha }} \
            --region ${{ secrets.REGION }} \
            --allow-unauthenticated \
            --add-cloudsql-instances "${{ secrets.INSTANCE_CONNECTION_NAME }}" \
            --set-env-vars "DATABASE_URL=${DATABASE_URL}"
